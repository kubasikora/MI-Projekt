{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytaj potrzebne biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.0.3\n",
      "numpy version: 1.18.4\n",
      "matplotlib version: 3.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.optimize import differential_evolution\n",
    "from sklearn import preprocessing\n",
    "\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"numpy version: {}\".format(np.__version__))\n",
    "print(\"matplotlib version: {}\".format(mpl.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytaj dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeDateToSeconds(df):\n",
    "    first = df[\"date\"][0]\n",
    "    df[\"date\"] = df[\"date\"].apply(lambda timestamp: (timestamp-first).seconds)\n",
    "    return df\n",
    "\n",
    "def readDataFromExcel(path, sheet):\n",
    "    df = pd.read_excel(path, sheet_name=sheet, na_values=[\" Bad Data\",\"Bad Data\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = changeDateToSeconds(df)\n",
    "    return df\n",
    "\n",
    "df2 = readDataFromExcel(\"./data/K-1_MI.xlsx\", \"d2\")\n",
    "df3 = readDataFromExcel(\"./data/K-1_MI.xlsx\", \"d3\")\n",
    "df5 = readDataFromExcel(\"./data/K-1_MI.xlsx\", \"d5\")\n",
    "df6 = readDataFromExcel(\"./data/K-1_MI.xlsx\", \"d6\")\n",
    "\n",
    "df6 = df6.iloc[::5, :] # dopasuj okresy próbkowania\n",
    "\n",
    "dataFrames = [df2, df3, df5, df6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skalowanie i oczyszczanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledDf = df2.append(df3).append(df5).append(df6)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaledDf = scaledDf.drop([\"date\"], axis=1)\n",
    "columns = scaledDf.columns\n",
    "\n",
    "scaler.fit(scaledDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledDataFrames = list()\n",
    "for df in dataFrames:\n",
    "    df = scaler.transform(df.drop([\"date\"], axis=1))\n",
    "    scaledDataFrames.append(pd.DataFrame(df, columns=columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzenie macierzy regresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareSignals(df, inputs, output, medfilt=False, kernelSize=11):\n",
    "    inputSignals = df[inputs]\n",
    "    outputSignal = df[output]\n",
    "    inputFrame = pd.concat([inputSignals, outputSignal.shift(1)], axis=1).iloc[1:]\n",
    "\n",
    "    if(medfilt == True):\n",
    "        u_signals = applyMedianFilter(inputFrame.to_numpy(), kernelSize)\n",
    "        y_signal = applyMedianFilter(df[output].iloc[1:].to_numpy(), kernelSize)\n",
    "\n",
    "    else:\n",
    "        u_signals = inputFrame.to_numpy()\n",
    "        y_signal =  df[output].iloc[1:].to_numpy()\n",
    "        \n",
    "    return (u_signals, y_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelMatrixForSingleInput(data, order, delay, exponent):\n",
    "    if(order < 0 or delay < 0 or exponent <= 0):\n",
    "        raise AssertionError(\"Invalid structure parameter\")\n",
    "        \n",
    "    samples = data.shape[0]\n",
    "    widthCoefficient = (order + 1)*exponent\n",
    "    heightAbsoluteTerm = order + delay\n",
    "    \n",
    "    A = np.zeros([samples - heightAbsoluteTerm, widthCoefficient])\n",
    "    \n",
    "    for j in range(order+1):\n",
    "        for k in range(exponent):\n",
    "            colIndex = (order-j)*exponent + k\n",
    "            A[:, colIndex] = np.power(data[j : samples-heightAbsoluteTerm+j], k+1)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxDelayAndOrder(M):\n",
    "    maxDelay = 0; maxOrder = 0\n",
    "    for index, parameters in enumerate(M.T):\n",
    "        order, delay, exponent = parameters\n",
    "        if(order > maxOrder):\n",
    "            maxOrder = order\n",
    "        if(delay > maxDelay):\n",
    "            maxDelay = delay\n",
    "    \n",
    "    return maxDelay, maxOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelMatrix(data, M):\n",
    "    if(M.shape[0] != 3):\n",
    "        raise AssertionError(\"Invalid parameter vector size\")\n",
    "\n",
    "    if(M.shape[1] != data.shape[1]):\n",
    "        raise AssertionError(\"Mismatched size of data: {} and M: {} vector\".format(data.shape, M.shape))\n",
    "        \n",
    "    inputs = M.shape[1]\n",
    "    height = data.shape[0]\n",
    "    \n",
    "    maxDelay, maxOrder = findMaxDelayAndOrder(M)\n",
    "    A = np.empty(shape=(height-maxOrder-maxDelay, 0)) \n",
    "    for index, parameters in enumerate(M.T):\n",
    "        # stworz macierz dla danego wejscia\n",
    "        inputData = data[:, index]\n",
    "        order, delay, exponent = parameters\n",
    "        Ap = createModelMatrixForSingleInput(data[:, index], order, delay, exponent)\n",
    "        \n",
    "        # obetnij macierz - delay od góry, a order od dołu macierzy\n",
    "        delayMaxDiff = np.abs(maxDelay-delay)\n",
    "        orderMaxDiff = np.abs(maxOrder-order)\n",
    "        baseHeight = Ap.shape[0]\n",
    "        validA = Ap[orderMaxDiff+delayMaxDiff:]\n",
    "        validA = validA[:A.shape[0]]\n",
    "        \n",
    "        # dodaj do akumulatora\n",
    "        A = np.concatenate((A, validA), axis=1)\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oblicz wynik modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModelScore(model, M, u_verif, y_verif):\n",
    "    maxDelay, maxOrder = findMaxDelayAndOrder(M)   \n",
    "    numberOfSamples = y_verif.shape[0]\n",
    "    output_verif_cut = y_verif[maxDelay : numberOfSamples - maxOrder]\n",
    "    \n",
    "    data_idx = maxOrder+maxDelay+1\n",
    "    u_verif_wip = np.array(u_verif[0:data_idx],copy=True)\n",
    "    A_verif = createModelMatrix(u_verif_wip, M)\n",
    "    \n",
    "    model_outputs = np.array([])\n",
    "    for i in range(data_idx, data_idx+len(output_verif_cut)):\n",
    "        output_model_verif = model.predict(A_verif)\n",
    "        model_outputs = np.append(model_outputs, output_model_verif)\n",
    "        u_verif_wip = np.vstack((u_verif_wip, u_verif[data_idx:data_idx+1]))[1:]\n",
    "        data_idx += 1\n",
    "        u_verif_wip[-1][-1] = output_model_verif[-1]\n",
    "        A_verif = createModelMatrix(u_verif_wip, M) \n",
    "        \n",
    "    verif_score = r2_score(output_verif_cut, model_outputs)\n",
    "    return verif_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(M, dataFrames, inputs, outputs):\n",
    "    maxDelay, maxOrder = findMaxDelayAndOrder(M)\n",
    "    regressors = inputs + outputs\n",
    "    scores = list()\n",
    "    for df_verif in dataFrames:\n",
    "        u_verif, y_verif = prepareSignals(df_verif, inputs, outputs)\n",
    "        A_learn = None\n",
    "        y_learn = None\n",
    "        for df_learn in dataFrames:\n",
    "            if df_verif.equals(df_learn):\n",
    "                continue\n",
    "            \n",
    "            u, y = prepareSignals(df_learn, inputs, outputs)\n",
    "            A = createModelMatrix(u, M)\n",
    "            \n",
    "            if A_learn is None:\n",
    "                A_learn = np.empty((0, A.shape[1]))\n",
    "            if y_learn is None:\n",
    "                y_learn = np.empty((0, y.shape[1]))\n",
    "            \n",
    "            numberOfSamples = y.shape[0]\n",
    "            y_cut = y[maxDelay : numberOfSamples - maxOrder]\n",
    "            A_learn = np.vstack((A_learn, A))\n",
    "            y_learn = np.vstack((y_learn, y_cut))\n",
    "        \n",
    "        \n",
    "        model = linear_model.LinearRegression().fit(A_learn, y_learn)\n",
    "        score = evalModelScore(model, M, u_verif, y_verif)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ręczne szukanie struktury modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uruchom algorytm genetyczny do znalezienia struktury modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"FWF\", \"PP\", \"DP\"]\n",
    "output = [\"LT01\"]\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def goalFunction(x):\n",
    "    # zbuduj macierz M na podstawie wektora x\n",
    "    M = np.empty(shape=(3, len(inputs) + 1), dtype=np.int32)\n",
    "    for index, value in enumerate(x):\n",
    "        row = index % 3; col = index // 3\n",
    "        M[row, col] = int(value)\n",
    "        \n",
    "    M_hash = hash(str(M))\n",
    "    if M_hash in cache:\n",
    "        score = cache[M_hash]\n",
    "    else:\n",
    "        score = crossValidate(M, scaledDataFrames, inputs, output)\n",
    "        cache[M_hash] = score\n",
    "        \n",
    "    return (-1)*score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= 0.0139437\n"
     ]
    }
   ],
   "source": [
    "bounds = [(0, 5), (0,30), (1, 2)]*(len(inputs) + 1)\n",
    "bounds[-2] = (1,1)\n",
    "result = differential_evolution(goalFunction, bounds, disp=True, polish=False, tol=10.0, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0ac921c19f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6957acb922c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "optimM = np.empty(shape=(3, len(inputs) + 1), dtype=np.int32)\n",
    "for index, value in enumerate(result.x):\n",
    "    row = index % 3; col = index // 3\n",
    "    optimM[row, col] = int(value)\n",
    "print(optimM)\n",
    "\n",
    "u_learn, y_learn = prepareSignals(scaledDataFrames[0], inputs, output)\n",
    "u_verif, y_verif = prepareSignals(scaledDataFrames[0], inputs, output)\n",
    "\n",
    "maxDelay, maxOrder = findMaxDelayAndOrder(optimM)   \n",
    "numberOfSamples = y_learn.shape[0]\n",
    "output_learn_cut = y_learn[maxDelay : numberOfSamples - maxOrder]\n",
    "output_verif_cut = y_verif[maxDelay : numberOfSamples - maxOrder]\n",
    "\n",
    "A_learn = createModelMatrix(u_learn, optimM)\n",
    "model = linear_model.LinearRegression().fit(A_learn, output_learn_cut)\n",
    "score = evalModelScore(model, optimM, u_verif, y_verif)\n",
    "\n",
    "print(model.coef_)\n",
    "\n",
    "maxDelay, maxOrder = findMaxDelayAndOrder(optimM)\n",
    "numberOfSamples = y_learn.shape[0]\n",
    "output_learn_cut = y_learn[maxDelay : numberOfSamples - maxOrder]\n",
    "output_verif_cut = y_verif[maxDelay : numberOfSamples - maxOrder]\n",
    "\n",
    "# A_verif = createModelMatrix(u_verif, optimM)\n",
    "A_learn = createModelMatrix(u_learn, optimM)\n",
    "y_model_learn = model.predict(A_learn)\n",
    "# y_model_verif = model.predict(A_verif)\n",
    "\n",
    "data_idx = maxOrder+maxDelay+1\n",
    "u_verif_wip = np.array(u_verif[0:data_idx],copy=True)\n",
    "A_verif = createModelMatrix(u_verif_wip, optimM)\n",
    "    \n",
    "model_outputs = np.array([])\n",
    "for i in range(data_idx, data_idx+len(output_learn_cut)):\n",
    "    output_model_verif = model.predict(A_verif)\n",
    "    model_outputs = np.append(model_outputs, output_model_verif)\n",
    "    u_verif_wip = np.vstack((u_verif_wip, u_verif[data_idx:data_idx+1]))[1:]\n",
    "    data_idx += 1\n",
    "    u_verif_wip[-1][-1] = output_model_verif[-1]\n",
    "    A_verif = createModelMatrix(u_verif_wip, optimM) \n",
    "        \n",
    "verif_score = r2_score(output_verif_cut, model_outputs)\n",
    "print(verif_score)\n",
    "\n",
    "# plot data\n",
    "fig, axs = plt.subplots(2,figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axs[0].plot(output_learn_cut)\n",
    "axs[0].plot(y_model_learn)\n",
    "axs[0].set_title(\"Dane uczące\")\n",
    "axs[1].plot(output_verif_cut)\n",
    "axs[1].plot(model_outputs)\n",
    "axs[1].set_title(\"Dane weryfikacyjne\")\n",
    "plt.rcParams['figure.figsize'] = [15, 20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
